{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_26Yig99f-l-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg \n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMQzoEBOMZfj"
   },
   "source": [
    "## Set up the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kq7eYIRvf1lb"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(202042)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TtaFMa9WWJPk"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True, use_metadata_server=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LwA1bEMof8Nh"
   },
   "outputs": [],
   "source": [
    "from src import training\n",
    "from src.models.unet import UNet\n",
    "from src.metrics import DiceLoss\n",
    "from src.image_mask_dataset import ImageMaskDataset, FullSubmissionImageDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFfuoa_CMqzi"
   },
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urOzMnkscDh8"
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "root_dir = \"/content/drive/Shareddrives/road-segmentation/data/\"\n",
    "image_dir = root_dir + \"training/images/\"\n",
    "gt_dir = root_dir + \"training/groundtruth/\"\n",
    "test_dir = root_dir + \"test_set_images/\"\n",
    "\n",
    "dataset = ImageMaskDataset(image_dir, gt_dir)\n",
    "\n",
    "# Perform data augmentation by rotation and shearing\n",
    "angles = [15, -10, 45, -60, 78]\n",
    "for angle in angles:\n",
    "    rotation = lambda img: TF.rotate(img, angle)\n",
    "    dataset += ImageMaskDataset(image_dir, gt_dir, rotation)\n",
    "\n",
    "shears = [[15, 20], [10, 30], [30, -17], [-3, 20], [-5, -10]]\n",
    "for shear in shears:\n",
    "    transformation = lambda img: TF.affine(img, angle=0, scale=1.0, translate=[0, 0], shear=shear)\n",
    "    dataset += ImageMaskDataset(image_dir, gt_dir, transformation)\n",
    "\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nL5ir_3lO3qS"
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "data_len = len(dataset)\n",
    "train_len = int(data_len * 0.8)\n",
    "test_len = int(data_len * 0.2)\n",
    "\n",
    "# Split the data in 80/20 for training and validation\n",
    "dataset_train, dataset_test = random_split(dataset, [train_len, test_len])\n",
    "print(len(dataset_train), len(dataset_test))\n",
    "\n",
    "# Load the data using a dataloader\n",
    "dataloader_train = DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rd_Vy9fvI1ZH"
   },
   "source": [
    "## Learning Rate Finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gCEjuI2LI0HZ"
   },
   "outputs": [],
   "source": [
    "!pip install torch-lr-finder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3Bub8hVJD0L"
   },
   "outputs": [],
   "source": [
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "NUM_CHANNELS = 3\n",
    "NUM_FILTERS = 64\n",
    "\n",
    "model = UNet(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# Use the LR-finder to find the optimal learning rate\n",
    "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
    "lr_finder.range_test(dataloader_train, end_lr=1, num_iter=100)\n",
    "lr_finder.plot() # Plot resuling graph: loss as a function of epochs \n",
    "lr_finder.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8O5OGG1eM9Om"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "enAQPKFtQr68"
   },
   "outputs": [],
   "source": [
    "#@title Setup\n",
    "# Name of the run:\n",
    "run_name = \"Unet_paper_Adam_Dice\"   #@param {type:\"string\"}\n",
    "# Path to the drive:\n",
    "drive_path = \"/content/drive/Shareddrives/road-segmentation/\"   #@param {type:\"string\"}\n",
    "# Stating epoch (if not 0 load model):\n",
    "starting_epoch = 0   #@param {type:\"integer\",  min:0}\n",
    "# Epoch step (number of epoch between each save):\n",
    "epoch_step = 10   #@param {type:\"integer\",  min:1}\n",
    "# Number of training Epoch\n",
    "total_iterations =     20#@param {type:\"integer\", min:1}\n",
    "# Learning rate (please run above cell and use best found):\n",
    "learning_rate = 5e-4 #@param {type:\"number\", min:1e-6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v1NG1MK8GNBu"
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3\n",
    "NUM_FILTERS = 64\n",
    "\n",
    "# decay_rate = 0.95\n",
    "\n",
    "# Initialize our model with the right optimizer\n",
    "model = UNet(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate, verbose=True)\n",
    "\n",
    "# Load the model if we're continuing training\n",
    "if starting_epoch > 0:\n",
    "    loading_model_file = run_name + f\"_{starting_epoch}.pkt\"\n",
    "\n",
    "    if loading_model_file in os.listdir(drive_path):\n",
    "        print(\"Loading model from \" + loading_model_file)\n",
    "        state_dicts = torch.load(drive_path + loading_model_file)\n",
    "        model.load_state_dict(state_dicts['model_state_dict'])\n",
    "        optimizer.load_state_dict(state_dicts['optimizer_state_dict'])\n",
    "#         scheduler.load_state_dict(state_dicts['scheduler_state_dict\"])\n",
    "    else:\n",
    "        print(\"Unable to load model from \" + loading_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8SQr7pqVqL1V"
   },
   "outputs": [],
   "source": [
    "for i in range(starting_epoch, total_iterations, epoch_step):\n",
    "    # Train the model for a step of epochs\n",
    "    accuracies, f1_scores, iou_scores = training.train(model, criterion, dataloader_train, dataloader_test, optimizer, num_epochs=epoch_step)\n",
    "\n",
    "    # Save the model's state\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "#               'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()},\n",
    "        drive_path + run_name + f\"_{i + epoch_step}.pkt\")\n",
    "\n",
    "    score_file_name = \"scores_\" + run_name + \".csv\"\n",
    "\n",
    "    # Save intermediate scores\n",
    "    if score_file_name not in os.listdir(drive_path):\n",
    "        with open(drive_path + score_file_name, \"w\") as f:\n",
    "            f.write(\"accuracy, f1_score, iou_score\\n\")\n",
    "\n",
    "    with open(drive_path + score_file_name, \"a\") as f:\n",
    "        for i in range(epoch_step):\n",
    "            f.write(f\"{accuracies[i]}, {f1_scores[i]}, {iou_scores[i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jhw_7axXB3o6"
   },
   "source": [
    "### Show predicted output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Mu_I2kH4mvn"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "# Show predicted outputs on the training images\n",
    "files = os.listdir(image_dir)\n",
    "img = mpimg.imread(image_dir + files[i])\n",
    "gt = mpimg.imread(gt_dir + files[i])\n",
    "output = model(torch.tensor(img).to(device).permute(2, 0, 1).view(1, 3, 400, 400))\n",
    "prediction = output[0][0].cpu().detach().numpy()\n",
    "\n",
    "from src.scripts.helpers import concatenate_images\n",
    "\n",
    "fig1 = plt.figure(figsize=(14, 10))\n",
    "plt.imshow(concatenate_images(concatenate_images(img, gt), prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_k_rX4ZFtuV"
   },
   "source": [
    "## Predict output for testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nYy4ATKo36m"
   },
   "outputs": [],
   "source": [
    "# Load the testing data\n",
    "submission_dataloader = DataLoader(\n",
    "    FullSubmissionImageDataset(test_dir),\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTqRe2YHkq89"
   },
   "outputs": [],
   "source": [
    "# Set the model in eval state\n",
    "model.eval()\n",
    "toPIL = transforms.ToPILImage()\n",
    "\n",
    "output_dir = \"outputs\"\n",
    "\n",
    "if output_dir not in os.listdir():\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Run predictions and save outputs\n",
    "for indexes, images in submission_dataloader:\n",
    "    out = model(images.to(device)).view(2, 608, 608).cpu()\n",
    "    toPIL(out[0]).save(output_dir + \"/file_{:03d}.png\".format(indexes.view(-1).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIHyfV8TuXMl"
   },
   "outputs": [],
   "source": [
    "# Create the submission.csv file\n",
    "masks_to_submission(\"submission.csv\", *[output_dir + \"/\" + f for f in os.listdir(output_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gFMe7e0d9O6Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "train_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
