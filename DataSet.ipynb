{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import torchvision.io as io\n",
    "import matplotlib.image as mpimg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/content/drive/Shareddrives/road-segmentation/data/\"\n",
    "img_path = root_dir + \"training/images/\"\n",
    "gt_path = root_dir + \"training/groundtruth/\"\n",
    "test_path = \"test_set_images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchedSatImagesDataset(Dataset):\n",
    "    img_size = (400, 400)\n",
    "    patch_size = (16, 16)\n",
    "    \n",
    "    def __init__(self, training_img_path, training_gt_path, foreground_threshold = None, transform = None):\n",
    "        \"\"\"\n",
    "        Dataset for the traing data, this dataset is already patched\n",
    "        \n",
    "        @param training_img_path    : (string)             path to the training sat images\n",
    "        @param training_gt_path     : (string)             path to the groundtruth images\n",
    "        @param foreground_threshold : (float, optional)     if a value is provided then the label is 1 if the mean of the patch is greater than this value. \n",
    "                                                           if no value is provided, the mean is returned as label\n",
    "        @param transform            : (callable, optional) a transformation to apply to each patch before returning it\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.files = [{\"sat\" : io.read_image(training_img_path + f), \"gt\" : torch.tensor(mpimg.imread(training_gt_path + f))} for f in sorted(os.listdir(training_img_path))]\n",
    "        self.foreground_threshold = foreground_threshold\n",
    "        self.transform = transform\n",
    "    \n",
    "    def patch_per_img(self):\n",
    "        return (self.img_size[0] // self.patch_size[0]) * (self.img_size[1] // self.patch_size[1])\n",
    "    \n",
    "    def __len__(self): \n",
    "        return len(self.files) * self.patch_per_img()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        files_number = idx // self.patch_per_img()\n",
    "        patch_number = idx % self.patch_per_img()\n",
    "        files = self.files[files_number]\n",
    "        sat_img = files[\"sat\"]\n",
    "        gt_img = files[\"gt\"]\n",
    "        row_number = patch_number // (self.img_size[0] // self.patch_size[0])\n",
    "        col_number = patch_number % (self.img_size[0] // self.patch_size[0])\n",
    "        \n",
    "        X = sat_img[:, row_number : row_number + self.patch_size[0], col_number : col_number + self.patch_size[1]] / 255\n",
    "        Y = torch.mean(gt_img[row_number : row_number + self.patch_size[0], col_number : col_number + self.patch_size[1]])\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        if self.foreground_threshold is not None:\n",
    "            if Y > self.foreground_threshold :\n",
    "                Y = 1\n",
    "            else :\n",
    "                Y = 0\n",
    "        \n",
    "        return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchedTestSatImagesDataset(Dataset):\n",
    "    img_size = (608, 608)\n",
    "    patch_size = (16, 16)\n",
    "    \n",
    "    def __init__(self, test_img_path, transform = None):\n",
    "        \"\"\"\n",
    "        Dataset for the testing data, this dataset is already patched\n",
    "        \n",
    "        @param test_img_path    : (string)             path to the testing sat images\n",
    "        @param transform        : (callable, optional) a transformation to apply to each patch before returning it\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.files = [io.read_image(test_img_path + f + \"/\" + f + \".png\") for f in sorted(os.listdir(test_img_path))]\n",
    "        self.transform = self.transform\n",
    "    \n",
    "    def patch_per_img(self):\n",
    "        return (self.img_size[0] // self.patch_size[0]) * (self.mg_size[1] // self.patch_size[1])\n",
    "    \n",
    "    def __len__(): \n",
    "        return len(self.files) * self.patch_per_img()\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        files_number = idx // self.patch_per_img()\n",
    "        patch_number = idx % self.patch_per_img()\n",
    "        sat_img = self.files[files_number]\n",
    "        row_number = patch_number // (self.img_size[0] // self.patch_size[0])\n",
    "        col_number = patch_number % (self.img_size[0] // self.patch_size[0])\n",
    "        \n",
    "        X = sat_img[:, row_number : row_number + self.patch_size[0], col_number : col_number + self.patch_size[1]] / 255\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            X = self.transform(X)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
