{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIxdBWEhcGk9",
        "jupyter": {
          "outputs_hidden": false
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os,sys\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, random_split\n",
        "import torchvision.io as io\n",
        "from torchvision import transforms \n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qXcCArMcGk-",
        "outputId": "3bc586e9-8b5f-48cb-e86f-fcdf12010939"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tt08z5avcZyl",
        "outputId": "a8a635c2-0e78-41c9-9a87-f4953f9edb1e"
      },
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True, use_metadata_server=False)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxMv4qyh9EuX"
      },
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    import requests\n",
        "    # Save datagenerators as file to colab working directory\n",
        "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
        "    url = 'https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/training.py?token=AFUMR6ANI6H6PQ6BZGQQI4C72E32O'\n",
        "    r = requests.get(url)\n",
        "\n",
        "    with open('training.py', 'w') as f:\n",
        "        f.write(r.text)\n",
        "\n",
        "    url = 'https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/MyDataSet.py?token=AFUMR6FXF63DZ6R24EZXE4K72E33E'\n",
        "    r = requests.get(url)\n",
        "        \n",
        "    with open('MyDataSet.py', 'w') as f:\n",
        "        f.write(r.text)\n",
        "        \n",
        "    import MyDataSet\n",
        "    import training \n",
        "else:\n",
        "    from src import training   \n",
        "    from src import MyDataSet"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv3In6TncGk-"
      },
      "source": [
        "threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
        "\n",
        "class PatchModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Model that tells if a 16 x 16 RGB (as a 3 x 16 x 16 tensor) correspond to a road (1) or not (0)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        # 3 channels 16 x 16\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=3,\n",
        "            out_channels=10,\n",
        "            kernel_size=5\n",
        "        )\n",
        "        # 10 channels 12 x 12 (12 = 16 - (kernel_size - 1))\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        # 10 channels 6 x 6 (6 = 12 / kernel_size)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=10,\n",
        "            out_channels=20,\n",
        "            kernel_size=3\n",
        "        )\n",
        "        # 20 channels 4 x 4 (4 = 6 - (kernel_size - 1))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        # 20 channels 2 x 2 (2 = 4 / kernel_size)\n",
        "        \n",
        "        self.lin1 = nn.Linear(\n",
        "            in_features=20 * 2 * 2,\n",
        "            out_features=10\n",
        "        )\n",
        "        self.lin2 = nn.Linear(\n",
        "            in_features=10,\n",
        "            out_features=1\n",
        "        )\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.pool1(self.conv1(x)))\n",
        "        x = self.relu(self.pool2(self.conv2(x)))\n",
        "        x = x.view(-1, 20 * 2 * 2)\n",
        "        x = self.relu(self.lin1(x))\n",
        "        x = self.sigmoid(self.lin2(x))\n",
        "        # If we are in testing mode then the output should be either 0 or 1\n",
        "        if not self.training:\n",
        "            x = 1 * (x > threshold)\n",
        "        return x.view(-1)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkSiH1B5NVFZ"
      },
      "source": [
        "#PyTorch\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(DiceLoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        # inputs = F.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        intersection = (inputs * targets).sum()                            \n",
        "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
        "        \n",
        "        return 1 - dice"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUTnVCa_PTcs"
      },
      "source": [
        "#PyTorch\n",
        "class IoULoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True):\n",
        "        super(IoULoss, self).__init__()\n",
        "\n",
        "    def forward(self, inputs, targets, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        # inputs = F.sigmoid(inputs)       \n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        #intersection is equivalent to True Positive count\n",
        "        #union is the mutually inclusive area of all labels & predictions \n",
        "        intersection = (inputs * targets).sum()\n",
        "        total = (inputs + targets).sum()\n",
        "        union = total - intersection \n",
        "        \n",
        "        IoU = (intersection + smooth)/(union + smooth)\n",
        "                \n",
        "        return 1 - IoU"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSI0n2ABcGk_"
      },
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 1e-1\n",
        "batch_size = 100\n",
        "\n",
        "dataset = MyDataSet.PatchedSatImagesDataset(MyDataSet.img_path, MyDataSet.gt_path, threshold)\n",
        "\n",
        "rotations = [(0, 45), (45, 90), (90, 135), (135, 180), (-45, 0), (-90, -45), (-135, -90), (-180, -135)]\n",
        "for rotation in rotations:\n",
        "    dataset += MyDataSet.PatchedSatImagesDataset(MyDataSet.img_path, MyDataSet.gt_path, threshold, transforms.RandomRotation(rotation))\n",
        "\n",
        "data_len = len(dataset)\n",
        "train_len = int(data_len * 0.7)\n",
        "test_len = int(data_len * 0.3)\n",
        "\n",
        "dataset_train, dataset_test = random_split(dataset, [train_len, test_len])\n",
        "\n",
        "print(len(dataset_train), len(dataset_test))\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    dataset_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Train the logistic regression model with the Adam optimizer\n",
        "criterion = torch.nn.BCELoss()\n",
        "model = PatchModel().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "training.train(model, criterion, dataloader_train, dataloader_test, optimizer, num_epochs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CmqUxexDcGk_"
      },
      "source": [
        "submission = MyDataSet.PatchedTestSatImagesDataset(MyDataSet.test_path)\n",
        "dataloader_submission = torch.utils.data.DataLoader(\n",
        "    submission, \n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")\n",
        "with open('submission.csv', 'w') as f:\n",
        "    f.write('id,prediction\\n')\n",
        "    model.eval()\n",
        "    for img_id, X in dataloader_submission:\n",
        "        X = X.to(device)\n",
        "        Y = model(X).item()\n",
        "        f.write(f'{img_id[0]},{Y}\\n')        "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pqp-0IU6iY9Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}