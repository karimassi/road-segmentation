{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_26Yig99f-l-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import torchvision.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from torchvision import transforms \n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kq7eYIRvf1lb",
    "outputId": "caad0f38-8997-444a-da54-77fd75defa19"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TtaFMa9WWJPk",
    "outputId": "f7fa077c-ec1e-49f5-df80-c3a9225b539b"
   },
   "outputs": [],
   "source": [
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True, use_metadata_server=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwA1bEMof8Nh"
   },
   "outputs": [],
   "source": [
    "def import_file(url, filename):\n",
    "  import requests\n",
    "  r = requests.get(url)\n",
    "\n",
    "  with open(filename, 'w') as f:\n",
    "        f.write(r.text)\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    # Save datagenerators as file to colab working directory\n",
    "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
    "    url_u_net = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net.py?token=AJVSYDHQIQ5KJXR6G5EH6NS7275YE'\n",
    "    import_file(url_u_net, 'u_net.py')\n",
    "\n",
    "    url_u_net_paper = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net_paper.py?token=AJVSYDDDE2ZOO2E5RKHSDNK7275ZI'\n",
    "    import_file(url_u_net_paper, 'u_net_paper.py')\n",
    "\n",
    "    url_training = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/training.py?token=AJVSYDBUQJXHKKCMQZTOC3272752S'\n",
    "    import_file(url_training, 'training.py')\n",
    "\n",
    "    url_image_mask_dataset = \"https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/image_mask_dataset.py?token=AJVSYDEYVNI34EBZZW6QMPK72753U\"\n",
    "    import_file(url_image_mask_dataset, 'image_mask_dataset.py')\n",
    "\n",
    "    url_losses = \"https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/losses.py?token=AJVSYDGGYYFBALHBYGZQM4S727546\"\n",
    "    import_file(url_losses, 'losses.py')\n",
    "\n",
    "    url_mask_to_submission = \"https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/scripts/mask_to_submission.py?token=AH35XE53LAD2Y6Y4NC4JCAC73DHIA\"\n",
    "    import_file(url_mask_to_submission, 'mask_to_submission.py')\n",
    "        \n",
    "    import u_net\n",
    "    import u_net_paper \n",
    "    import training\n",
    "    import image_mask_dataset\n",
    "    import losses\n",
    "    from mask_to_submission import masks_to_submission\n",
    "else:\n",
    "    from src import u_net\n",
    "    from src import u_net_paper\n",
    "    from src import training\n",
    "    from src import image_mask_dataset\n",
    "    from src import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "urOzMnkscDh8",
    "outputId": "51b4d388-218d-494a-b3a1-fd6ea32f4bfe"
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "from image_mask_dataset import ImageMaskDataset\n",
    "\n",
    "root_dir = \"/content/drive/Shareddrives/road-segmentation/data/\"\n",
    "image_dir = root_dir + \"training/images/\"\n",
    "gt_dir = root_dir + \"training/groundtruth/\"\n",
    "test_dir = root_dir + \"test_set_images/\"\n",
    "\n",
    "# TODO change implementation of this dataset\n",
    "dataset = ImageMaskDataset(image_dir, gt_dir, 0)\n",
    "\n",
    "# apply transformations\n",
    "rotations = [5, 10, 15, 27, 32, 44, 50, 59, 63, 70, 86, 90, 100, 120, -30, -45, -90]\n",
    "for angle in rotations:\n",
    "    dataset += ImageMaskDataset(image_dir, gt_dir, angle)\n",
    "\n",
    "#dataset += ImageMaskDataset(image_dir, gt_dir, transforms.RandomVerticalFlip(p = 1.0))\n",
    "#dataset += ImageMaskDataset(image_dir, gt_dir, transforms.RandomHorizontalFlip(p = 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nL5ir_3lO3qS",
    "outputId": "26145278-4566-4a1e-b785-b56f31ad1be7"
   },
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "learning_rate = 1e-3\n",
    "batch_size = 5\n",
    "\n",
    "data_len = len(dataset)\n",
    "train_len = int(data_len * 0.9)\n",
    "test_len = int(data_len * 0.1)\n",
    "\n",
    "dataset_train, dataset_test = random_split(dataset, [train_len, test_len])\n",
    "print(len(dataset_train), len(dataset_test))\n",
    "\n",
    "dataloader_train = torch.utils.data.DataLoader(\n",
    "    dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "dataloader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v1NG1MK8GNBu",
    "outputId": "5fc13ae0-db71-4693-f07c-f7f9b83db0b4"
   },
   "outputs": [],
   "source": [
    "import u_net_paper\n",
    "from u_net_paper import UNet_paper\n",
    "\n",
    "NUM_CHANNELS = 3\n",
    "NUM_FILTERS = 32\n",
    "\n",
    "model = UNet_paper(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loading_model_file = \"u_net_100.pkt\"\n",
    "\n",
    "if loading_model_file in os.listdir():\n",
    "    print(\"Loading model from \" + loading_model_file)\n",
    "    model.load_state_dict(torch.load(loading_model_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llYxAWGhiLk9",
    "outputId": "7e79e834-c128-4cec-f448-2f3bd983bd93"
   },
   "outputs": [],
   "source": [
    "import training\n",
    "\n",
    "# Train the u-net model with the SGD optimizer\n",
    "criterion = losses.Dice()\n",
    "\n",
    "training.train(model, criterion, dataloader_train, dataloader_test, optimizer, num_epochs)\n",
    "\n",
    "#from torchsummary import summary\n",
    "#summary(model, input_size=(NUM_CHANNELS, 400, 400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBBaPsmKo9PX"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"u_net_120.pkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_nYy4ATKo36m"
   },
   "outputs": [],
   "source": [
    "import image_mask_dataset\n",
    "submission_dataloader = DataLoader(\n",
    "    image_mask_dataset.FullSubmissionImageDataset(test_dir),\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tTqRe2YHkq89"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "toPIL = transforms.ToPILImage()\n",
    "\n",
    "output_dir = \"outputs\"\n",
    "\n",
    "if output_dir not in os.listdir():\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "for indexes, images in submission_dataloader:\n",
    "    out = model(images.to(device)).view(2, 608, 608).cpu()\n",
    "    toPIL(out[0]).save(output_dir + \"/file_{:03d}.png\".format(indexes.view(-1).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RIHyfV8TuXMl"
   },
   "outputs": [],
   "source": [
    "masks_to_submission(\"submission.csv\", *[output_dir + \"/\" + f for f in os.listdir(output_dir)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FwsprI8i7Rcx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "train_models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
