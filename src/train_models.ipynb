{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_26Yig99f-l-"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import os,sys\n",
        "import numpy as np\n",
        "import torchvision.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torchvision import transforms \n",
        "from torch.utils.data import Dataset, random_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq7eYIRvf1lb",
        "outputId": "1c42436c-44c1-4a29-b979-2211a92d5c05"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwA1bEMof8Nh",
        "outputId": "aa447640-7012-47c9-b272-bd55d9f0d585"
      },
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True, use_metadata_server=False)\n",
        "    \n",
        "def import_file(url, filename):\n",
        "  import requests\n",
        "  r = requests.get(url)\n",
        "\n",
        "  with open(filename, 'w') as f:\n",
        "        f.write(r.text)\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Save datagenerators as file to colab working directory\n",
        "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
        "    url_u_net = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net.py?token=AJVSYDCYFSNCXQW2B5UOPG27ZJREK'\n",
        "    import_file(url_u_net, 'u_net.py')\n",
        "\n",
        "    url_u_net_paper = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net_paper.py?token=AJVSYDBJJBS6FXDVBFXKV7S7ZJRGY'\n",
        "    import_file(url_u_net_paper, 'u_net_paper.py')\n",
        "\n",
        "    url_training = 'https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/training.py?token=AFUMR6FMXJI4DQHDQGBSNEK7YYMNU'\n",
        "    import_file(url_training, 'training.py')\n",
        "\n",
        "    url_image_mask_dataset = \"https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/image_mask_dataset.py?token=AJVSYDDNI2HGBE2YKVRZXFK7ZWOBA\"\n",
        "    import_file(url_image_mask_dataset, 'image_mask_dataset.py')\n",
        "        \n",
        "    import u_net\n",
        "    import u_net_paper \n",
        "    import training\n",
        "    import image_mask_dataset\n",
        "else:\n",
        "    from src import u_net\n",
        "    from src import u_net_paper\n",
        "    from src import training\n",
        "    from src import image_mask_dataset"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "llYxAWGhiLk9",
        "outputId": "ee114ac9-423e-48cd-a4e2-f6ade7bddaa1"
      },
      "source": [
        "import image_mask_dataset\n",
        "\n",
        "root_dir = \"/content/drive/Shareddrives/road-segmentation/data/training/\"\n",
        "image_dir = root_dir + \"images/\"\n",
        "gt_dir = root_dir + \"groundtruth/\"\n",
        "\n",
        "num_epochs = 10\n",
        "learning_rate = 1e-3\n",
        "batch_size = 5\n",
        "\n",
        "dataset = image_mask_dataset.ImageMaskDataset(image_dir, gt_dir)\n",
        "\n",
        "data_len = len(dataset)\n",
        "train_len = int(data_len * 0.2)\n",
        "test_len = int(data_len * 0.8)\n",
        "\n",
        "dataset_train, dataset_test = random_split(dataset, [train_len, test_len])\n",
        "print(len(dataset_train), len(dataset_test))\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    dataset_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "from u_net import UNet\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_FILTERS = 32\n",
        "\n",
        "# TODO: implement training for u-net model\n",
        "# Train the logistic regression model with the Adam optimizer\n",
        "criterion = torch.nn.MSELoss()\n",
        "model = UNet(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
        "\n",
        "#from torchsummary import summary\n",
        "#summary(model, input_size=(NUM_CHANNELS, 400, 400))\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "training.train(model, criterion, dataloader_train, dataloader_test, optimizer, num_epochs)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 80\n",
            "Starting training\n",
            "Epoch  1 | Test accuracy : 0.0 | Test F1 : 0.27441\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-649a67b4290f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, dataset_train, dataset_test, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Compute the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;31m# Update the parameters of the model with a gradient step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}