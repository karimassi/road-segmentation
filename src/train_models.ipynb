{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_26Yig99f-l-",
        "outputId": "12963096-8dc4-4c71-b4a4-c50a3dff5b7d"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import os,sys\n",
        "import numpy as np\n",
        "import torchvision.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torchvision import transforms \n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq7eYIRvf1lb",
        "outputId": "b387c3da-7532-4e4b-f33b-1cff3c683612"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtaFMa9WWJPk",
        "outputId": "b7aeb9bf-1abd-4422-fb4d-9b56c2faae18"
      },
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True, use_metadata_server=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwA1bEMof8Nh",
        "outputId": "067aeea7-a9c4-4155-80f1-4812f4d8880d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def import_file(url, filename):\n",
        "  import requests\n",
        "  r = requests.get(url)\n",
        "\n",
        "  with open(filename, 'w') as f:\n",
        "        f.write(r.text)\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Save datagenerators as file to colab working directory\n",
        "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
        "    url_u_net = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net.py?token=AJVSYDHQIQ5KJXR6G5EH6NS7275YE'\n",
        "    import_file(url_u_net, 'u_net.py')\n",
        "\n",
        "    url_u_net_paper = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net_paper.py?token=AJVSYDDDE2ZOO2E5RKHSDNK7275ZI'\n",
        "    import_file(url_u_net_paper, 'u_net_paper.py')\n",
        "\n",
        "    url_training = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/training.py?token=AJVSYDBUQJXHKKCMQZTOC3272752S'\n",
        "    import_file(url_training, 'training.py')\n",
        "\n",
        "    url_image_mask_dataset = \"https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/image_mask_dataset.py?token=AJVSYDEYVNI34EBZZW6QMPK72753U\"\n",
        "    import_file(url_image_mask_dataset, 'image_mask_dataset.py')\n",
        "\n",
        "    url_losses = \"https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/losses.py?token=AJVSYDGGYYFBALHBYGZQM4S727546\"\n",
        "    import_file(url_losses, 'losses.py')\n",
        "\n",
        "    url_mask_to_submission = \"https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/scripts/mask_to_submission.py?token=AH35XE53LAD2Y6Y4NC4JCAC73DHIA\"\n",
        "    import_file(url_mask_to_submission, 'mask_to_submission.py')\n",
        "        \n",
        "    import u_net\n",
        "    import u_net_paper \n",
        "    import training\n",
        "    import image_mask_dataset\n",
        "    import losses\n",
        "    from mask_to_submission import masks_to_submission\n",
        "else:\n",
        "    from src import u_net\n",
        "    from src import u_net_paper\n",
        "    from src import training\n",
        "    from src import image_mask_dataset\n",
        "    from src import losses"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[autoreload of image_mask_dataset failed: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
            "    superreload(m, reload, self.old_objects)\n",
            "RecursionError: maximum recursion depth exceeded\n",
            "]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urOzMnkscDh8"
      },
      "source": [
        "# load data\n",
        "from image_mask_dataset import ImageMaskDataset\n",
        "\n",
        "root_dir = \"/content/drive/Shareddrives/road-segmentation/data/\"\n",
        "image_dir = root_dir + \"training/images/\"\n",
        "gt_dir = root_dir + \"training/groundtruth/\"\n",
        "test_dir = root_dir + \"test_set_images/\"\n",
        "\n",
        "# TODO change implementation of this dataset\n",
        "dataset = ImageMaskDataset(image_dir, gt_dir, 0)\n",
        "\n",
        "# apply transformations\n",
        "rotations = [5, 10, 15, 27, 32, 44, 50, 59, 63, 70, 86, 90, 100, 120, -30, -45, -90]\n",
        "for angle in rotations:\n",
        "    dataset += ImageMaskDataset(image_dir, gt_dir, angle)\n",
        "\n",
        "#dataset += ImageMaskDataset(image_dir, gt_dir, transforms.RandomVerticalFlip(p = 1.0))\n",
        "#dataset += ImageMaskDataset(image_dir, gt_dir, transforms.RandomHorizontalFlip(p = 1.0))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llYxAWGhiLk9",
        "outputId": "4586c917-851d-499c-92d9-b5402a877b47"
      },
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 1e-3\n",
        "batch_size = 5\n",
        "\n",
        "data_len = len(dataset)\n",
        "train_len = int(data_len * 0.9)\n",
        "test_len = int(data_len * 0.1)\n",
        "\n",
        "dataset_train, dataset_test = random_split(dataset, [train_len, test_len])\n",
        "print(len(dataset_train), len(dataset_test))\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    dataset_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "import u_net_paper\n",
        "from u_net_paper import UNet_paper\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_FILTERS = 32\n",
        "\n",
        "import training\n",
        "\n",
        "# Train the u-net model with the SGD optimizer\n",
        "model = UNet_paper(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
        "criterion = losses.Dice()\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "training.train(model, criterion, dataloader_train, dataloader_test, optimizer, num_epochs)\n",
        "\n",
        "#from torchsummary import summary\n",
        "#summary(model, input_size=(NUM_CHANNELS, 400, 400))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1620 180\n",
            "Starting training\n",
            "Epoch  1 | Test accuracy : 0.5277 | Test F1 : 0.43537 | In 55.628790616989136 s\n",
            "Epoch  2 | Test accuracy : 0.64849 | Test F1 : 0.46152 | In 55.60875844955444 s\n",
            "Epoch  3 | Test accuracy : 0.64751 | Test F1 : 0.48876 | In 55.615922927856445 s\n",
            "Epoch  4 | Test accuracy : 0.61817 | Test F1 : 0.51301 | In 55.60984468460083 s\n",
            "Epoch  5 | Test accuracy : 0.50257 | Test F1 : 0.5285 | In 55.61926317214966 s\n",
            "Epoch  6 | Test accuracy : 0.45284 | Test F1 : 0.53936 | In 55.60362696647644 s\n",
            "Epoch  7 | Test accuracy : 0.44829 | Test F1 : 0.54638 | In 55.617098808288574 s\n",
            "Epoch  8 | Test accuracy : 0.44817 | Test F1 : 0.55101 | In 55.60003852844238 s\n",
            "Epoch  9 | Test accuracy : 0.44817 | Test F1 : 0.55429 | In 55.61407947540283 s\n",
            "Epoch  10 | Test accuracy : 0.44817 | Test F1 : 0.55707 | In 55.60509538650513 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBBaPsmKo9PX"
      },
      "source": [
        "torch.save(model, \"u_net.pkt\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nYy4ATKo36m"
      },
      "source": [
        "import image_mask_dataset\n",
        "submission_dataloader = DataLoader(\n",
        "    image_mask_dataset.FullSubmissionImageDataset(test_dir),\n",
        "    batch_size=1\n",
        ")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTqRe2YHkq89"
      },
      "source": [
        "model.eval()\n",
        "toPIL = transforms.ToPILImage()\n",
        "\n",
        "output_dir = \"outputs\"\n",
        "\n",
        "if output_dir not in os.listdir():\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for indexes, images in submission_dataloader:\n",
        "    out = model(images.to(device)).view(2, 608, 608).cpu()\n",
        "    toPIL(out[0]).save(output_dir + \"/file_{:03d}.png\".format(indexes.view(-1).item()))"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIHyfV8TuXMl"
      },
      "source": [
        "masks_to_submission(\"submission.csv\", *[output_dir + \"/\" + f for f in os.listdir(output_dir)])"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwsprI8i7Rcx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}