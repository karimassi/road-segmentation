{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_26Yig99f-l-"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import os,sys\n",
        "import numpy as np\n",
        "import torchvision.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from torchvision import transforms \n",
        "from torch.utils.data import Dataset, random_split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kq7eYIRvf1lb",
        "outputId": "49f32750-465a-4e52-8abd-3ba6628b6724"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtaFMa9WWJPk",
        "outputId": "eb7df4ef-478f-4435-ecea-a6fd55ff7420"
      },
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True, use_metadata_server=False)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwA1bEMof8Nh",
        "outputId": "9cb0c8d0-d2ca-4ce4-8456-503bb542d3c9"
      },
      "source": [
        "def import_file(url, filename):\n",
        "  import requests\n",
        "  r = requests.get(url)\n",
        "\n",
        "  with open(filename, 'w') as f:\n",
        "        f.write(r.text)\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Save datagenerators as file to colab working directory\n",
        "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
        "    url_u_net = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net.py?token=AJVSYDCYFSNCXQW2B5UOPG27ZJREK'\n",
        "    import_file(url_u_net, 'u_net.py')\n",
        "\n",
        "    url_u_net_paper = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/models/u_net_paper.py?token=AJVSYDBJJBS6FXDVBFXKV7S7ZJRGY'\n",
        "    import_file(url_u_net_paper, 'u_net_paper.py')\n",
        "\n",
        "    url_training = 'https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/training.py?token=AJVSYDBJO3AY5WONIKOAU4K7Z7QIO'\n",
        "    import_file(url_training, 'training.py')\n",
        "\n",
        "    url_image_mask_dataset = \"https://raw.githubusercontent.com/karimassi/road-segmentation/u_net/src/image_mask_dataset.py?token=AJVSYDDNI2HGBE2YKVRZXFK7ZWOBA\"\n",
        "    import_file(url_image_mask_dataset, 'image_mask_dataset.py')\n",
        "        \n",
        "    import u_net\n",
        "    import u_net_paper \n",
        "    import training\n",
        "    import image_mask_dataset\n",
        "else:\n",
        "    from src import u_net\n",
        "    from src import u_net_paper\n",
        "    from src import training\n",
        "    from src import image_mask_dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urOzMnkscDh8"
      },
      "source": [
        "# load data\n",
        "import image_mask_dataset\n",
        "\n",
        "root_dir = \"/content/drive/Shareddrives/road-segmentation/data/training/\"\n",
        "image_dir = root_dir + \"images/\"\n",
        "gt_dir = root_dir + \"groundtruth/\"\n",
        "\n",
        "dataset = image_mask_dataset.ImageMaskDataset(image_dir, gt_dir)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llYxAWGhiLk9",
        "outputId": "8c7af85d-5a3c-450b-9232-67cd1429c944"
      },
      "source": [
        "num_epochs = 10\n",
        "learning_rate = 1e-5\n",
        "batch_size = 5\n",
        "\n",
        "data_len = len(dataset)\n",
        "train_len = int(data_len * 0.9)\n",
        "test_len = int(data_len * 0.1)\n",
        "\n",
        "dataset_train, dataset_test = random_split(dataset, [train_len, test_len])\n",
        "print(len(dataset_train), len(dataset_test))\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    dataset_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "import u_net_paper\n",
        "from u_net_paper import UNet_paper\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_FILTERS = 32\n",
        "\n",
        "import training\n",
        "\n",
        "# Train the u-net model with the SGD optimiz\n",
        "model = UNet_paper(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "training.train(model, dataloader_train, dataloader_test, optimizer, num_epochs)\n",
        "\n",
        "#from torchsummary import summary\n",
        "#summary(model, input_size=(NUM_CHANNELS, 400, 400))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90 10\n",
            "Starting training\n",
            "Epoch  1 | Test accuracy : 0.0 | Test F1 : 0.46024\n",
            "Epoch  2 | Test accuracy : 0.0 | Test F1 : 0.46257\n",
            "Epoch  3 | Test accuracy : 0.0 | Test F1 : 0.46418\n",
            "Epoch  4 | Test accuracy : 0.0 | Test F1 : 0.46454\n",
            "Epoch  5 | Test accuracy : 0.0 | Test F1 : 0.46423\n",
            "Epoch  6 | Test accuracy : 0.0 | Test F1 : 0.46412\n",
            "Epoch  7 | Test accuracy : 0.0 | Test F1 : 0.46457\n",
            "Epoch  8 | Test accuracy : 0.0 | Test F1 : 0.46461\n",
            "Epoch  9 | Test accuracy : 0.0 | Test F1 : 0.46442\n",
            "Epoch  10 | Test accuracy : 0.0 | Test F1 : 0.46459\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}