{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "train_models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_26Yig99f-l-"
      },
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import os,sys\n",
        "import numpy as np\n",
        "import torchvision.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg \n",
        "import torchvision.transforms.functional as TF\n",
        "from torch.utils.data import Dataset, random_split, DataLoader\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMQzoEBOMZfj"
      },
      "source": [
        "# *Set up environment* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq7eYIRvf1lb"
      },
      "source": [
        "torch.manual_seed(202042)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtaFMa9WWJPk"
      },
      "source": [
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True, use_metadata_server=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwA1bEMof8Nh"
      },
      "source": [
        "def import_file(url, filename):\n",
        "  import requests\n",
        "  r = requests.get(url)\n",
        "\n",
        "  with open(filename, 'w') as f:\n",
        "        f.write(r.text)\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    # Save datagenerators as file to colab working directory\n",
        "    # If you are using GitHub, make sure you get the \"Raw\" version of the code\n",
        "    url_u_net = 'https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/models/u_net.py?token=AH35XEZLG77J44LJEI3JUA273MJ3Y'\n",
        "    import_file(url_u_net, 'u_net.py')\n",
        "\n",
        "    url_u_net_paper = 'https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/models/u_net_paper.py?token=AH35XE3C7J2MEAJUDPPB7NS73MJ44'\n",
        "    import_file(url_u_net_paper, 'u_net_paper.py')\n",
        "\n",
        "    url_training = 'https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/training.py?token=AH35XE4C3I6GA76R5S52S6K73MJ6O'\n",
        "    import_file(url_training, 'training.py')\n",
        "\n",
        "    url_image_mask_dataset = \"https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/image_mask_dataset.py?token=AH35XEZ6S76B5H677BWENH273MJ7O\"\n",
        "    import_file(url_image_mask_dataset, 'image_mask_dataset.py')\n",
        "\n",
        "    url_losses = \"https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/losses.py?token=AH35XE7IQIBGM4BD6Y5WKC273MKA2\"\n",
        "    import_file(url_losses, 'losses.py')\n",
        "\n",
        "    url_mask_to_submission = \"https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/scripts/mask_to_submission.py?token=AH35XE4CSULUVJL4W77YT3S73MKCE\"\n",
        "    import_file(url_mask_to_submission, 'mask_to_submission.py')\n",
        "\n",
        "    url_helpers = \"https://raw.githubusercontent.com/karimassi/road-segmentation/main/src/scripts/helpers.py?token=AH35XE6XSPSCRLSVMFJL7JS73MKES\"\n",
        "    import_file(url_helpers, 'helpers.py')\n",
        "        \n",
        "    import u_net\n",
        "    import u_net_paper \n",
        "    import training\n",
        "    import image_mask_dataset\n",
        "    import losses\n",
        "    from mask_to_submission import masks_to_submission\n",
        "    import helpers\n",
        "else:\n",
        "    from src import u_net\n",
        "    from src import u_net_paper\n",
        "    from src import training\n",
        "    from src import image_mask_dataset\n",
        "    from src import losses\n",
        "    from src import helpers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFfuoa_CMqzi"
      },
      "source": [
        "# **Load data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urOzMnkscDh8"
      },
      "source": [
        "# load data\n",
        "from image_mask_dataset import ImageMaskDataset\n",
        "\n",
        "root_dir = \"/content/drive/Shareddrives/road-segmentation/data/\"\n",
        "image_dir = root_dir + \"training/images/\"\n",
        "gt_dir = root_dir + \"training/groundtruth/\"\n",
        "test_dir = root_dir + \"test_set_images/\"\n",
        "\n",
        "dataset = ImageMaskDataset(image_dir, gt_dir)\n",
        "\n",
        "# data augmentation\n",
        "angles = [15, -10, 45, -60, 78]\n",
        "for angle in angles:\n",
        "    rotation = lambda img: TF.rotate(img, angle)\n",
        "    dataset += ImageMaskDataset(image_dir, gt_dir, rotation)\n",
        "\n",
        "shears = [[15, 20], [10, 30], [30, -17], [-3, 20], [-5, -10]]\n",
        "for shear in shears:\n",
        "  transformation = lambda img: TF.affine(img, angle=0, scale=1.0, translate=[0, 0], shear=shear)\n",
        "  dataset += ImageMaskDataset(image_dir, gt_dir, transformation)\n",
        "\n",
        "print(len(dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL5ir_3lO3qS"
      },
      "source": [
        "batch_size = 5\n",
        "\n",
        "data_len = len(dataset)\n",
        "train_len = int(data_len * 0.8)\n",
        "test_len = int(data_len * 0.2)\n",
        "\n",
        "dataset_train, dataset_test = random_split(dataset, [train_len, test_len])\n",
        "print(len(dataset_train), len(dataset_test))\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(\n",
        "    dataset_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "dataloader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rd_Vy9fvI1ZH"
      },
      "source": [
        "# ***Learning Rate Finder***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCEjuI2LI0HZ"
      },
      "source": [
        "!pip install torch-lr-finder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Bub8hVJD0L"
      },
      "source": [
        "from torch_lr_finder import LRFinder\n",
        "from u_net_paper import UNet_paper\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_FILTERS = 64\n",
        "\n",
        "model = UNet_paper(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
        "\n",
        "criterion = losses.Dice()#torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-6)\n",
        "\n",
        "lr_finder = LRFinder(model, optimizer, criterion, device=\"cuda\")\n",
        "lr_finder.range_test(dataloader_train, end_lr=1, num_iter=100)\n",
        "lr_finder.plot() # to inspect the loss-learning rate graph\n",
        "lr_finder.reset() # to reset the model and optimizer to their initial state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O5OGG1eM9Om"
      },
      "source": [
        "# ***Train model***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "enAQPKFtQr68"
      },
      "source": [
        "#@title Setup\n",
        "# Name of the run:\n",
        "run_name = \"Unet_paper_Adam_Dice\"   #@param {type:\"string\"}\n",
        "# Path to the drive:\n",
        "drive_path = \"/content/drive/Shareddrives/road-segmentation/\"   #@param {type:\"string\"}\n",
        "# Stating epoch (if not 0 load model):\n",
        "starting_epoch = 0   #@param {type:\"integer\",  min:0}\n",
        "# Epoch step (number of epoch between each save):\n",
        "epoch_step = 10   #@param {type:\"integer\",  min:1}\n",
        "# Number of training Epoch\n",
        "total_iterations =     20#@param {type:\"integer\", min:1}\n",
        "# Learning rate (please run above cell and use best found):\n",
        "learning_rate = 5e-4 #@param {type:\"number\", min:1e-6}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1NG1MK8GNBu"
      },
      "source": [
        "from u_net_paper import UNet_paper\n",
        "\n",
        "NUM_CHANNELS = 3\n",
        "NUM_FILTERS = 64\n",
        "\n",
        "#decay_rate = 0.95\n",
        "\n",
        "model = UNet_paper(NUM_CHANNELS, NUM_FILTERS).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "#scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer=optimizer, gamma=decay_rate, verbose=True)\n",
        "\n",
        "if starting_epoch > 0:\n",
        "    loading_model_file = run_name + f\"_{starting_epoch}.pkt\"\n",
        "\n",
        "    if loading_model_file in os.listdir(drive_path):\n",
        "        print(\"Loading model from \" + loading_model_file)\n",
        "        state_dicts = torch.load(drive_path + loading_model_file)\n",
        "        model.load_state_dict(state_dicts['model_state_dict'])\n",
        "        optimizer.load_state_dict(state_dicts['optimizer_state_dict'])\n",
        "        #scheduler.load_state_dict(state_dicts['scheduler_state_dict\"])\n",
        "    else :\n",
        "      print(\"Unable to load model from \" + loading_model_file)\n",
        "\n",
        "#from torchsummary import summary\n",
        "#summary(model, input_size=(NUM_CHANNELS, 400, 400))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SQr7pqVqL1V"
      },
      "source": [
        "import training\n",
        "\n",
        "for i in range(starting_epoch, total_iterations, epoch_step):\n",
        "    accuracies, f1_scores, iou_scores = training.train(model, criterion, dataloader_train, dataloader_test, optimizer, num_epochs=epoch_step)\n",
        "\n",
        "    torch.save(\n",
        "        {\n",
        "          'model_state_dict': model.state_dict(),\n",
        "          #'scheduler_state_dict': scheduler.state_dict(),\n",
        "          'optimizer_state_dict': optimizer.state_dict()\n",
        "        },\n",
        "        drive_path + run_name + f\"_{i + epoch_step}.pkt\"\n",
        "    )\n",
        "\n",
        "\n",
        "    score_file_name = \"scores_\" + run_name + \".csv\"\n",
        "\n",
        "    if score_file_name not in os.listdir(drive_path):\n",
        "        with open(drive_path + score_file_name, \"w\") as f:\n",
        "          f.write(\"accuracy, f1_score, iou_score\\n\")\n",
        "\n",
        "    with open(drive_path + score_file_name, \"a\") as f:\n",
        "        for i in range(epoch_step):\n",
        "            f.write(f\"{accuracies[i]}, {f1_scores[i]}, {iou_scores[i]}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jhw_7axXB3o6"
      },
      "source": [
        "### Show predicted output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Mu_I2kH4mvn"
      },
      "source": [
        "i = 0\n",
        "\n",
        "files = os.listdir(image_dir)\n",
        "img = mpimg.imread(image_dir + files[i])\n",
        "gt = mpimg.imread(gt_dir + files[i])\n",
        "output = model(torch.tensor(img).to(device).permute(2, 0, 1).view(1, 3, 400, 400))\n",
        "prediction = output[0][0].cpu().detach().numpy()\n",
        "\n",
        "from helpers import concatenate_images\n",
        "fig1 = plt.figure(figsize=(14, 10))\n",
        "plt.imshow(concatenate_images(concatenate_images(img, gt), prediction))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_k_rX4ZFtuV"
      },
      "source": [
        "# **Predict output for testing images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nYy4ATKo36m"
      },
      "source": [
        "import image_mask_dataset\n",
        "submission_dataloader = DataLoader(\n",
        "    image_mask_dataset.FullSubmissionImageDataset(test_dir),\n",
        "    batch_size=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTqRe2YHkq89"
      },
      "source": [
        "from torchvision import transforms\n",
        "model.eval()\n",
        "toPIL = transforms.ToPILImage()\n",
        "\n",
        "output_dir = \"outputs\"\n",
        "\n",
        "if output_dir not in os.listdir():\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for indexes, images in submission_dataloader:\n",
        "    out = model(images.to(device)).view(2, 608, 608).cpu()\n",
        "    toPIL(out[0]).save(output_dir + \"/file_{:03d}.png\".format(indexes.view(-1).item()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIHyfV8TuXMl"
      },
      "source": [
        "masks_to_submission(\"submission.csv\", *[output_dir + \"/\" + f for f in os.listdir(output_dir)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFMe7e0d9O6Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}